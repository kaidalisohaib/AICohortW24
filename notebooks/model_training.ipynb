{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaidalisohaib/AICohortW24/blob/Anton/notebooks/model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waifusAK8aT7"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM4tSWaW8aT9"
      },
      "source": [
        "### Step 1: Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BtnHVdAw8aUB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG5lBZS-8aUC"
      },
      "source": [
        "### Step 2: Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gnTXIfbS8aUC",
        "outputId": "ca2aaf0a-b9bb-4626-f6bc-eb91f73d2864",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   HeartDiseaseorAttack  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
            "0                   0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
            "1                   0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
            "2                   0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
            "3                   0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
            "4                   0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
            "\n",
            "   Diabetes  PhysActivity  Fruits  ...  AnyHealthcare  NoDocbcCost  GenHlth  \\\n",
            "0       0.0           0.0     0.0  ...            1.0          0.0      5.0   \n",
            "1       0.0           1.0     0.0  ...            0.0          1.0      3.0   \n",
            "2       0.0           0.0     1.0  ...            1.0          1.0      5.0   \n",
            "3       0.0           1.0     1.0  ...            1.0          0.0      2.0   \n",
            "4       0.0           1.0     1.0  ...            1.0          0.0      2.0   \n",
            "\n",
            "   MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  Income  \n",
            "0      18.0      15.0       1.0  0.0   9.0        4.0     3.0  \n",
            "1       0.0       0.0       0.0  0.0   7.0        6.0     1.0  \n",
            "2      30.0      30.0       1.0  0.0   9.0        4.0     8.0  \n",
            "3       0.0       0.0       0.0  0.0  11.0        3.0     6.0  \n",
            "4       3.0       0.0       0.0  0.0  11.0        5.0     4.0  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ],
      "source": [
        "# File path to the dataset\n",
        "file_path = \"https://raw.githubusercontent.com/kaidalisohaib/AICohortW24/main/data/heart_disease_health_indicators_BRFSS2015.csv\"\n",
        "\n",
        "# Using pandas to read CSV file\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display it (remove at the end)\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSN_rEdQ8aUC"
      },
      "source": [
        "### Step 3: Data exploration\n",
        "TODO: Explore the dataset, check for missing values, data types, summary statistics, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JCXs2pPb8aUC",
        "outputId": "466fce72-ca8b-4e5e-db53-51fcc239b8b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of the data: (253680, 22)\n",
            "\n",
            "*********************************************\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 253680 entries, 0 to 253679\n",
            "Data columns (total 22 columns):\n",
            " #   Column                Non-Null Count   Dtype  \n",
            "---  ------                --------------   -----  \n",
            " 0   HeartDiseaseorAttack  253680 non-null  float64\n",
            " 1   HighBP                253680 non-null  float64\n",
            " 2   HighChol              253680 non-null  float64\n",
            " 3   CholCheck             253680 non-null  float64\n",
            " 4   BMI                   253680 non-null  float64\n",
            " 5   Smoker                253680 non-null  float64\n",
            " 6   Stroke                253680 non-null  float64\n",
            " 7   Diabetes              253680 non-null  float64\n",
            " 8   PhysActivity          253680 non-null  float64\n",
            " 9   Fruits                253680 non-null  float64\n",
            " 10  Veggies               253680 non-null  float64\n",
            " 11  HvyAlcoholConsump     253680 non-null  float64\n",
            " 12  AnyHealthcare         253680 non-null  float64\n",
            " 13  NoDocbcCost           253680 non-null  float64\n",
            " 14  GenHlth               253680 non-null  float64\n",
            " 15  MentHlth              253680 non-null  float64\n",
            " 16  PhysHlth              253680 non-null  float64\n",
            " 17  DiffWalk              253680 non-null  float64\n",
            " 18  Sex                   253680 non-null  float64\n",
            " 19  Age                   253680 non-null  float64\n",
            " 20  Education             253680 non-null  float64\n",
            " 21  Income                253680 non-null  float64\n",
            "dtypes: float64(22)\n",
            "memory usage: 42.6 MB\n",
            "\n",
            "*********************************************\n",
            "\n",
            "Are there any missing points in the dataset?: False\n",
            "\n",
            "*********************************************\n",
            "\n",
            "Number of Duplicated Rows: 23899\n",
            "\n",
            "*********************************************\n",
            "\n",
            "Size without doubles: 229781\n",
            "\n",
            "*********************************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display the dimension (rows/ columns)\n",
        "print(\"Dimension of the data:\", df.shape)\n",
        "print(\"\\n*********************************************\\n\")\n",
        "\n",
        "# Displaying concise summary of features in the dataset,\n",
        "# including the number of non-null values and data types\n",
        "df.info()\n",
        "print(\"\\n*********************************************\\n\")\n",
        "# Checking if there are any missing values (NaN) in the dataset and printing the result\n",
        "print(\"Are there any missing points in the dataset?:\", df.isnull().values.any())\n",
        "print(\"\\n*********************************************\\n\")\n",
        "# Counting the number of duplicated rows in the DataFrame and printing the result\n",
        "print(\"Number of Duplicated Rows:\", df.duplicated().sum())\n",
        "sizeNoDoubles = len(df) - df.duplicated().sum()\n",
        "# Remove duplicate row from dataset\n",
        "# df.drop_duplicates(keep='first', inplace=True)\n",
        "print(\"\\n*********************************************\\n\")\n",
        "print(\"Size without doubles:\", sizeNoDoubles)\n",
        "print(\"\\n*********************************************\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfPUCfx38aUD"
      },
      "source": [
        "### Step 4: Data preprocessing\n",
        "TODO: Handle missing values, encode categorical variables, perform feature scaling, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQ82UOYZ8aUD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjwv--aL8aUD"
      },
      "source": [
        "### Step 5: Data visualization\n",
        "TODO: Visualize the data to gain insights (e.g., histograms, scatter plots, correlation matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRi98HM_8aUD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLuYRSOj8aUE"
      },
      "source": [
        "### Step 6: Split the dataset into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln6LnEYJ8aUE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSGktgkB8aUE"
      },
      "source": [
        "### Step 7: Feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDjf1pJj8aUE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqTmb63Y8aUF"
      },
      "source": [
        "### Step 8: Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKf-f2YV8aUF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4d3zgkl8aUF"
      },
      "source": [
        "### Step 9: Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrWUe_ND8aUF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP0TvApi8aUF"
      },
      "source": [
        "### Step 10: Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpRUbHYv8aUF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPDEMtzN8aUG"
      },
      "source": [
        "### Step 11: Classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhMxWCaI8aUG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}